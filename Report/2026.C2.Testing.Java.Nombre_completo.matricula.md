# Reporte de Pruebas Automatizadas: SauceDemo

**Nombre Completo:** [Tu Nombre Completo]
**Matrícula:** [Tu Matrícula]
**Materia/Curso:** 2026.C2.Testing.Java

---

## 1. Portada

- **Proyecto:** Pruebas E2E en SauceDemo (https://www.saucedemo.com)
- **Herramientas Utilizadas:** Selenium (Java) y Cypress
- **Objetivo:** Iniciar sesión con los 6 usuarios de prueba proporcionados, agregar 4 artículos al carrito, validar el estado del carrito, generar logs en consola, y tomar capturas de pantalla de los resultados. Además, implementar el manejo de excepciones para los usuarios con errores intencionales de la plataforma.

---

## 2. Desarrollo

Se dividió el proyecto en dos enfoques principales y se organizó en carpetas separadas:

### 2.1 Enfoque 1: Selenium con Java (`/Selenium-Java`)

Se creó un proyecto en Maven utilizando JUnit 5 y WebDriverManager para facilitar la configuración del Chrome Driver.

**Configuración (`pom.xml`):**
Se agregaron dependencias para `selenium-java`, `webdrivermanager` y `junit-jupiter`. 

**Implementación (`SauceDemoTest.java`):**
Mediante un `@ParameterizedTest`, se itera sobre la lista de 6 usuarios.
- **Acciones:** Login, espera explícita (`WebDriverWait`), agregar hasta 4 elementos y verificación del `shopping_cart_badge`.
- **Manejo de Errores:** Usuarios como `locked_out_user` fueron validados mediante comprobación del mensaje emergente de error. Para usuarios como `problem_user` o `error_user` (que interceptan los clics) se capturaron excepciones para no quebrar la ejecución de las demás pruebas.
- **Capturas:** Al finalizar el escenario exitoso o la captura de una excepción, se toman capturas (*screenshots*) automatizadas y se guardan en la carpeta `/screenshots`.

**Comandos para ejecutar:**
1. Navegar a la carpeta: `cd Selenium-Java`
2. Ejecutar tests con Maven: `mvn test`

---

### 2.2 Enfoque 2: Cypress (`/Cypress-Testing`)

Se inicializó un proyecto de NPM y se instaló Cypress localmente.

**Configuración (`cypress.config.js`):**
Se configuró el soporte para imprimir logs directamente en la terminal de Node mediante la función `on('task', { log(message)... })`. Asimismo, se deshabilitó el video y se configuró la carpeta de capturas de pantalla. Además, se añadió una regla a nivel de prueba (`Cypress.on('uncaught:exception')`) para evitar que fallos del código interno de SauceDemo para el usuario `error_user` hicieran fallar a la suite.

**Implementación (`saucedemo.cy.js`):**
Se iteró sobre los 6 usuarios mediante un bloque `describe` y `it` dinámico.
- **Acciones:** `cy.visit`, login, iteración de los contenedores `.inventory_item` para buscar los botones de _"Add to cart"_ en los primeros 4 ítems.
- **Manejo de Tiempos y UI:** A diferencia de Selenium, Cypress espera implícitamente a los elementos de UI, haciendo el script mucho más limpio.
- **Capturas:** Configurado para tomar automáticamente capturas de pantalla si una aserción falla, así como capturas manuales (`cy.screenshot()`) para dejar evidencia del final del recorrido de compra.

**Comandos para ejecutar (CLI Headless):**
1. Navegar a la carpeta: `cd Cypress-Testing`
2. Ejecutar Cypress: `npx cypress run`

*(Los resultados y logs se verán en consola, y las capturas estarán en la carpeta `/cypress/screenshots`)*

---

## 3. Conclusiones

La automatización de un mismo flujo E2E (_End to End_) en dos herramientas diferentes permite contrastar enormemente sus enfoques:

1. **Selenium Java (Imperativo):** Requiere configuración explícita del Driver (WebDriverManager), tiempos de espera (`WebDriverWait`) y dependencias (Mvn, JUnit). Es altamente estricto, lo cual lo hace potente pero a la vez requiere mayor mantenimiento y código repetitivo para esperar elementos.
2. **Cypress (Declarativo y Asíncrono):** Su configuración con JSON/JS es sumamente sencilla. Emula al usuario de una manera natural en la web moderna e inyecta esperas por defecto que reducen la "flakiness" de las pruebas. Además, resolver problemas técnicos de la propia página (como excepciones internas) requirió solo interceptar el error a nivel del test runner sin ensuciar la lógica de negocio.

Como se pudo comprobar gracias al set de datos proporcionado, las pruebas se comportan diferente para cada caso de uso: algunos inician correctamente, algunos toman mucho tiempo para cargar y otros envían errores intencionales. Manejar estos escenarios fallidos es esencial para la estabilidad de cualquier pipeline de CI/CD.

---

**Liga del Repositorio (Git):** 
`[Inserta el link de tu repositorio aquí]`
